{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "160204099_Problem#1_Ass2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkJoaNy5ehv1"
      },
      "source": [
        "#**Problem 1 Bengali Handwritten Digits**\r\n",
        "\r\n",
        "The English handwritten digit recognition is one of the most popular problems in machine learning and computer vision. This problem is solved using various techniques. In this assignment, we will classify Bengali Handwritten Digits using logistic regression.\r\n",
        " \r\n",
        "Handwritten Digits classification can be used in various applications like optical character recognition, restore text from old documents, etc.\r\n",
        "In this assignment our main goal will be to achieve a good result using logistic regression and tuning hyperparameters correctly to get a better result.\r\n",
        " \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#**Dataset**\r\n",
        "\r\n",
        "\r\n",
        "> For this experiment, we will use the dataset [NumtaDB](https://www.kaggle.com/BengaliAI/numta/) which is available in **Kaggle**. \r\n",
        "There will be a total of **54908** images, and it was split in a **90:10** ratio. **90%** (**49417**) of data is used in training and **10%** (**5491**) was used in testing.\r\n",
        "\r\n",
        "#Snapshot of Dataset\r\n",
        "\r\n",
        "> <div align=\"center\">\r\n",
        "<img src=\"https://drive.google.com/uc?id=1LvkNwV1My2RniR_JsbasBET1fa97eMQu\" width=\"500\">\r\n",
        "</div>\r\n",
        "\r\n",
        "#**Experimental Setup**\r\n",
        "\r\n",
        "\r\n",
        "> All of these experiments were performed using Google Colab free GPU, Models were created in PyTorch. \r\n",
        "\r\n",
        "\r\n",
        "During the whole experiment,\r\n",
        "* The height and width of the input was **28*28 =784** \r\n",
        "* Output dimension was **(০,১,২,৩,৪,৫,৬,৭,৮,৯)=10**\r\n",
        "* Each batch size was different if each setting\r\n",
        "* The number of iteration was **15000**\r\n",
        "* Different activation function was used \r\n",
        "* GPU **Tesla T4** was availabe\r\n",
        "* Number of Epochs was different if each setting\r\n",
        "\r\n",
        "- **totaldata:** 54908\r\n",
        "  - $epochs = iterations \\div \\frac{totaldata}{minibatch}  $\r\n",
        "\r\n",
        "We will use different learning rate to achieve better performance\r\n",
        "\r\n",
        "# **Result**\r\n",
        "\r\n",
        "\r\n",
        "| Experiment Number      | Optimizer     | Learning Rate     |  Num of Hidden Layer   | Btach Size |Num of epoch    | |  Accurecy of last 1000 iterations    |\r\n",
        "| :------------- | :----------: |:----------: | :-----------: | :-----------:  | :-----------: || :-----------: |\r\n",
        "|  1 |SGD   | 0.09 | 4| 128 | 38   ||72.93  |\r\n",
        "|  2 |SGD   | 0.5 | 4| 256 | 77   ||77.52  |\r\n",
        "|  3 |SGD   | 0.11 | 4| 128 | 38   ||76.12  |\r\n",
        "|  4 |SGD   | 0.04 | 4| 512 | 155   ||80.84  |\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brAAsWgLSiBd"
      },
      "source": [
        "**Download Dataset Direct From Kaggle**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "Wc-nUmgRboWo",
        "outputId": "83953d0d-102f-4040-c79f-6596140c50da"
      },
      "source": [
        "!pip install kaggle\r\n",
        "from google.colab import files\r\n",
        "files.upload()\r\n",
        "!mkdir -p ~/.kaggle\r\n",
        "!cp kaggle.json ~/.kaggle/\r\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.10)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2020.12.5)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-89892120-4e32-4c7b-ade4-8759c9df0542\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-89892120-4e32-4c7b-ade4-8759c9df0542\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gxns8PIZakG"
      },
      "source": [
        "**Importing All Important Library**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k1yj1YAbzoe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95b475d0-a35e-4e4d-816c-85c05176f70d"
      },
      "source": [
        "import os \r\n",
        "import zipfile \r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "import shutil \r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torchvision.datasets as dsets\r\n",
        "from PIL import *\r\n",
        "from torch.utils.data import Dataset\r\n",
        "print(torch.cuda.get_device_name())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRMsKAhOZju8"
      },
      "source": [
        "**Download Kaggle Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxF3ZJeUc7kD",
        "outputId": "08992b64-4de3-46db-f303-918404dd1c84"
      },
      "source": [
        "!kaggle datasets download -d BengaliAI/numta"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading numta.zip to /content\n",
            "100% 1.91G/1.91G [00:18<00:00, 34.0MB/s]\n",
            "100% 1.91G/1.91G [00:18<00:00, 111MB/s] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkaL7xq3aJ07"
      },
      "source": [
        "**Unzip Dataset and Create new local Directory**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNHgldcBb3Ur"
      },
      "source": [
        "local_dir='/content/numta.zip'\r\n",
        "zip_ref=zipfile.ZipFile(local_dir,'r')\r\n",
        "extract_loc='/tmp'\r\n",
        "zip_ref.extractall(extract_loc)\r\n",
        "zip_ref.close\r\n",
        "TRAIN_PATH=\"/tmp/train\"\r\n",
        "os.mkdir(TRAIN_PATH)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjkPfcMLaQu4"
      },
      "source": [
        "**Function For Copying Image and Merging CSV**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilB2ceudcBlw"
      },
      "source": [
        "def copy_image(src,ls):\r\n",
        "  for image in ls:\r\n",
        "    file_name = os.path.join(src, image)\r\n",
        "    if os.path.isfile(file_name):\r\n",
        "      shutil.copy(file_name, TRAIN_PATH)  \r\n",
        "def merge_csv(path,col_list):\r\n",
        "  df=pd.read_csv(path,usecols=col_list)\r\n",
        "  merged_csv_new = pd.concat(df)      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vW9huJK_adv9"
      },
      "source": [
        "**Reading and Merging CSV**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rnveqlUcIAP"
      },
      "source": [
        "col_list = [\"filename\", \"digit\"]\r\n",
        "folder=os.listdir(extract_loc)\r\n",
        "csv_name=[]\r\n",
        "for files in folder:\r\n",
        "  if files.endswith(\".csv\")  and not files.startswith(\"training-b\") and not files.startswith(\"training-e\"):\r\n",
        "    path=extract_loc+\"/\"+files\r\n",
        "    df=pd.read_csv(path,usecols=col_list)\r\n",
        "    csv_name.append(df)\r\n",
        "merged_csv = pd.concat(csv_name,ignore_index=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sY3-3t3xaiaR"
      },
      "source": [
        "**Copying Image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrvQMgqccKFf"
      },
      "source": [
        "folder=os.listdir(extract_loc)\r\n",
        "for files in folder:\r\n",
        "  if files.startswith(\"training\") and not files.endswith(\".csv\") and not files.startswith(\"training-b\") and not files.startswith(\"training-e\") :\r\n",
        "    path=extract_loc+\"/\"+files\r\n",
        "    src = path + '/'\r\n",
        "    copy_image(src,os.listdir(path))\r\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3qfFfOLam0v"
      },
      "source": [
        "**Function For Dataset Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-h_V26fSLR3T"
      },
      "source": [
        "class Dataset(Dataset):\r\n",
        "    def __init__(self, df, root, transform=None):\r\n",
        "        self.data = df\r\n",
        "        self.root = root\r\n",
        "        self.transform = transform\r\n",
        "        \r\n",
        "    def __len__(self):\r\n",
        "        return len(self.data)\r\n",
        "    \r\n",
        "    def __getitem__(self, index):\r\n",
        "        item = self.data.iloc[index]\r\n",
        "        path = self.root + \"/\" + item[0]\r\n",
        "        image = Image.open(path).convert('L')\r\n",
        "        label = item[1]\r\n",
        "        if self.transform is not None:\r\n",
        "            image = self.transform(image)\r\n",
        "            \r\n",
        "        return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wthywlyDLbEK"
      },
      "source": [
        "train_transform = transforms.Compose([\r\n",
        "    transforms.Resize(28),\r\n",
        "    transforms.ToTensor(),\r\n",
        "    transforms.Normalize(0.5, 0.5)\r\n",
        "])\r\n",
        "\r\n",
        "dataset  = Dataset(merged_csv, TRAIN_PATH, train_transform)\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOuuB6W9azKd"
      },
      "source": [
        "**Displaying Image and Label**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "i4-dTHMz0xcx",
        "outputId": "5c55ed68-685a-488c-9d7b-48f0d9ebcea3"
      },
      "source": [
        "show_img = dataset[1][0].numpy().reshape(28, 28)\r\n",
        "plt.imshow(show_img, cmap='gray')\r\n",
        "print(\"Trainig label: \",dataset[1][1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trainig label:  3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDvFaRHc_SVQ"
      },
      "source": [
        "**Train and Test Data Split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7hXdHhYlDp_"
      },
      "source": [
        "train_dataset, test_dataset = train_test_split(dataset, test_size = 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bx2Yyipy133L"
      },
      "source": [
        "**1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hDhdvCjjJ1f",
        "outputId": "4b0a4c8c-5800-400e-e035-9629a2294fbe"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torchvision.datasets as dsets\r\n",
        "\r\n",
        "# Hyperparameters\r\n",
        "batch_size = 128\r\n",
        "num_iters = 15000\r\n",
        "input_dim = 28*28 # num_features = 784\r\n",
        "#num_hidden = 100\r\n",
        "output_dim = 10\r\n",
        "\r\n",
        "learning_rate = 0.09\r\n",
        "\r\n",
        "# Device\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "num_epochs = num_iters / (len(train_dataset) / batch_size)\r\n",
        "num_epochs = int(num_epochs)\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \r\n",
        "                                           batch_size=batch_size, \r\n",
        "                                           shuffle=True)   # It's better to shuffle the whole training dataset! \r\n",
        "\r\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \r\n",
        "                                          batch_size=batch_size, \r\n",
        "                                          shuffle=False) \r\n",
        "\r\n",
        "class DeepNeuralNetworkModel(nn.Module):\r\n",
        "    def __init__(self, input_size, num_classes, num_hidden):\r\n",
        "        super().__init__()\r\n",
        "        ### 1st hidden layer: 784 --> 128\r\n",
        "        self.linear_1 = nn.Linear(input_size, num_hidden)\r\n",
        "        ### Non-linearity in 1st hidden layer\r\n",
        "        self.relu_1 = nn.SELU()\r\n",
        "\r\n",
        "        ### 2nd hidden layer: 128 --> 128\r\n",
        "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\r\n",
        "        ### Non-linearity in 2nd hidden layer\r\n",
        "        self.relu_2 =  nn.SELU()\r\n",
        "\r\n",
        "        ### 3rd hidden layer: 128 --> 128\r\n",
        "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\r\n",
        "        ### Non-linearity in 3rd hidden layer\r\n",
        "        self.relu_3 =  nn.SELU()\r\n",
        "\r\n",
        "\r\n",
        "        ### 4th hidden layer: 128 --> 128\r\n",
        "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\r\n",
        "        ### Non-linearity in 4th hidden layer\r\n",
        "        self.relu_4 =  nn.SELU()\r\n",
        "\r\n",
        "        ### Output layer: 128 --> 10\r\n",
        "        self.linear_out = nn.Linear(num_hidden, num_classes)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        ### 1st hidden layer\r\n",
        "        out  = self.linear_1(x)\r\n",
        "        ### Non-linearity in 1st hidden layer\r\n",
        "        out = self.relu_1(out)\r\n",
        "        \r\n",
        "        ### 2nd hidden layer\r\n",
        "        out  = self.linear_2(out)\r\n",
        "        ### Non-linearity in 2nd hidden layer\r\n",
        "        out = self.relu_2(out)\r\n",
        "\r\n",
        "        ### 3rd hidden layer\r\n",
        "        out  = self.linear_3(out)\r\n",
        "        ### Non-linearity in 3rd hidden layer\r\n",
        "        out = self.relu_3(out)\r\n",
        "        \r\n",
        "        ### 4th hidden layer\r\n",
        "        out  = self.linear_4(out)\r\n",
        "        ### Non-linearity in 4th hidden layer\r\n",
        "        out = self.relu_4(out)\r\n",
        "\r\n",
        "        # Linear layer (output)\r\n",
        "        probas  = self.linear_out(out)\r\n",
        "        return probas\r\n",
        "\r\n",
        "# INSTANTIATE MODEL CLASS\r\n",
        "\r\n",
        "model = DeepNeuralNetworkModel(input_size = input_dim,\r\n",
        "                               num_classes = output_dim,\r\n",
        "                               num_hidden = 128)\r\n",
        "# To enable GPU\r\n",
        "model.to(device)\r\n",
        "\r\n",
        "# INSTANTIATE LOSS & OPTIMIZER CLASS\r\n",
        "\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\r\n",
        "\r\n",
        "iter = 0\r\n",
        "for epoch in range(num_epochs):\r\n",
        "    for i, (images, labels) in enumerate(train_loader):\r\n",
        "\r\n",
        "        images = images.view(-1, 28*28).to(device)\r\n",
        "        labels = labels.to(device)\r\n",
        "\r\n",
        "        # Clear gradients w.r.t. parameters\r\n",
        "        optimizer.zero_grad()\r\n",
        "\r\n",
        "        # Forward pass to get output/logits\r\n",
        "        outputs = model(images) \r\n",
        "\r\n",
        "        # Calculate Loss: softmax --> cross entropy loss\r\n",
        "        loss = criterion(outputs, labels)\r\n",
        "\r\n",
        "        # Getting gradients w.r.t. parameters\r\n",
        "        loss.backward()\r\n",
        "\r\n",
        "        # Updating parameters\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        iter += 1\r\n",
        "\r\n",
        "        if iter % 1000 == 0:\r\n",
        "            # Calculate Accuracy         \r\n",
        "            correct = 0\r\n",
        "            total = 0\r\n",
        "            # Iterate through test dataset\r\n",
        "            for images, labels in test_loader:\r\n",
        "               \r\n",
        "                images = images.view(-1, 28*28).to(device)\r\n",
        "\r\n",
        "                # Forward pass only to get logits/output\r\n",
        "                outputs = model(images)\r\n",
        "\r\n",
        "                # Get predictions from the maximum value\r\n",
        "                _, predicted = torch.max(outputs, 1)\r\n",
        "\r\n",
        "                # Total number of labels\r\n",
        "                total += labels.size(0)\r\n",
        "\r\n",
        "\r\n",
        "                # Total correct predictions\r\n",
        "                if torch.cuda.is_available():\r\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum() \r\n",
        "                else:\r\n",
        "                    correct += (predicted == labels).sum()\r\n",
        "\r\n",
        "            accuracy = 100 * correct.item() / total\r\n",
        "\r\n",
        "            # Print Loss\r\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 1000. Loss: 2.1579363346099854. Accuracy: 28.41012566017119\n",
            "Iteration: 2000. Loss: 1.9997174739837646. Accuracy: 33.80076488799854\n",
            "Iteration: 3000. Loss: 2.1141440868377686. Accuracy: 33.70970679293389\n",
            "Iteration: 4000. Loss: 1.987943172454834. Accuracy: 32.12529593880896\n",
            "Iteration: 5000. Loss: 1.7649571895599365. Accuracy: 37.9894372609725\n",
            "Iteration: 6000. Loss: 1.3171846866607666. Accuracy: 54.74412675286833\n",
            "Iteration: 7000. Loss: 1.7650419473648071. Accuracy: 49.20779457293754\n",
            "Iteration: 8000. Loss: 1.2184234857559204. Accuracy: 47.4412675286833\n",
            "Iteration: 9000. Loss: 1.0898027420043945. Accuracy: 65.015479876161\n",
            "Iteration: 10000. Loss: 0.956459641456604. Accuracy: 72.13622291021672\n",
            "Iteration: 11000. Loss: 0.926159143447876. Accuracy: 65.05190311418686\n",
            "Iteration: 12000. Loss: 2.1487927436828613. Accuracy: 44.87342924786014\n",
            "Iteration: 13000. Loss: 0.7554488182067871. Accuracy: 77.52686213804407\n",
            "Iteration: 14000. Loss: 0.7926562428474426. Accuracy: 72.93753414678565\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7akXd5RH173U"
      },
      "source": [
        "**2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hU_rXb0xon1S",
        "outputId": "c3d11bd7-fd77-473f-ea3a-e48586abc3c2"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torchvision.datasets as dsets\r\n",
        "\r\n",
        "# Hyperparameters\r\n",
        "batch_size = 256\r\n",
        "num_iters = 15000\r\n",
        "input_dim = 28*28 # num_features = 784\r\n",
        "#num_hidden = 100\r\n",
        "output_dim = 10\r\n",
        "\r\n",
        "learning_rate = 0.05\r\n",
        "\r\n",
        "# Device\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "num_epochs = num_iters / (len(train_dataset) / batch_size)\r\n",
        "num_epochs = int(num_epochs)\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \r\n",
        "                                           batch_size=batch_size, \r\n",
        "                                           shuffle=True)   # It's better to shuffle the whole training dataset! \r\n",
        "\r\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \r\n",
        "                                          batch_size=batch_size, \r\n",
        "                                          shuffle=False) \r\n",
        "\r\n",
        "class DeepNeuralNetworkModel(nn.Module):\r\n",
        "    def __init__(self, input_size, num_classes, num_hidden):\r\n",
        "        super().__init__()\r\n",
        "        ### 1st hidden layer: 784 --> 128\r\n",
        "        self.linear_1 = nn.Linear(input_size, num_hidden)\r\n",
        "        ### Non-linearity in 1st hidden layer\r\n",
        "        self.selu_1 = nn.SELU()\r\n",
        "\r\n",
        "        ### 2nd hidden layer: 128 --> 128\r\n",
        "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\r\n",
        "        ### Non-linearity in 2nd hidden layer\r\n",
        "        self.selu_2 = nn.SELU()\r\n",
        "\r\n",
        "        ### 3rd hidden layer: 128 --> 128\r\n",
        "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\r\n",
        "        ### Non-linearity in 3rd hidden layer\r\n",
        "        self.selu_3 = nn.SELU()\r\n",
        "\r\n",
        "\r\n",
        "        ### 4th hidden layer: 128 --> 128\r\n",
        "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\r\n",
        "        ### Non-linearity in 4th hidden layer\r\n",
        "        self.selu_4 = nn.SELU()\r\n",
        "\r\n",
        "        ### Output layer: 128 --> 10\r\n",
        "        self.linear_out = nn.Linear(num_hidden, num_classes)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        ### 1st hidden layer\r\n",
        "        out  = self.linear_1(x)\r\n",
        "        ### Non-linearity in 1st hidden layer\r\n",
        "        out = self.selu_1(out)\r\n",
        "        \r\n",
        "        ### 2nd hidden layer\r\n",
        "        out  = self.linear_2(out)\r\n",
        "        ### Non-linearity in 2nd hidden layer\r\n",
        "        out = self.selu_2(out)\r\n",
        "\r\n",
        "        ### 3rd hidden layer\r\n",
        "        out  = self.linear_3(out)\r\n",
        "        ### Non-linearity in 3rd hidden layer\r\n",
        "        out = self.selu_3(out)\r\n",
        "        \r\n",
        "        ### 4th hidden layer\r\n",
        "        out  = self.linear_4(out)\r\n",
        "        ### Non-linearity in 4th hidden layer\r\n",
        "        out = self.selu_4(out)\r\n",
        "\r\n",
        "        # Linear layer (output)\r\n",
        "        probas  = self.linear_out(out)\r\n",
        "        return probas\r\n",
        "\r\n",
        "# INSTANTIATE MODEL CLASS\r\n",
        "\r\n",
        "model = DeepNeuralNetworkModel(input_size = input_dim,\r\n",
        "                               num_classes = output_dim,\r\n",
        "                               num_hidden = 128)\r\n",
        "# To enable GPU\r\n",
        "model.to(device)\r\n",
        "\r\n",
        "# INSTANTIATE LOSS & OPTIMIZER CLASS\r\n",
        "\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\r\n",
        "\r\n",
        "iter = 0\r\n",
        "for epoch in range(num_epochs):\r\n",
        "    for i, (images, labels) in enumerate(train_loader):\r\n",
        "\r\n",
        "        images = images.view(-1, 28*28).to(device)\r\n",
        "        labels = labels.to(device)\r\n",
        "\r\n",
        "        # Clear gradients w.r.t. parameters\r\n",
        "        optimizer.zero_grad()\r\n",
        "\r\n",
        "        # Forward pass to get output/logits\r\n",
        "        outputs = model(images) \r\n",
        "\r\n",
        "        # Calculate Loss: softmax --> cross entropy loss\r\n",
        "        loss = criterion(outputs, labels)\r\n",
        "\r\n",
        "        # Getting gradients w.r.t. parameters\r\n",
        "        loss.backward()\r\n",
        "\r\n",
        "        # Updating parameters\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        iter += 1\r\n",
        "\r\n",
        "        if iter % 1000 == 0:\r\n",
        "            # Calculate Accuracy         \r\n",
        "            correct = 0\r\n",
        "            total = 0\r\n",
        "            # Iterate through test dataset\r\n",
        "            for images, labels in test_loader:\r\n",
        "               \r\n",
        "                images = images.view(-1, 28*28).to(device)\r\n",
        "\r\n",
        "                # Forward pass only to get logits/output\r\n",
        "                outputs = model(images)\r\n",
        "\r\n",
        "                # Get predictions from the maximum value\r\n",
        "                _, predicted = torch.max(outputs, 1)\r\n",
        "\r\n",
        "                # Total number of labels\r\n",
        "                total += labels.size(0)\r\n",
        "\r\n",
        "\r\n",
        "                # Total correct predictions\r\n",
        "                if torch.cuda.is_available():\r\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum() \r\n",
        "                else:\r\n",
        "                    correct += (predicted == labels).sum()\r\n",
        "\r\n",
        "            accuracy = 100 * correct.item() / total\r\n",
        "\r\n",
        "            # Print Loss\r\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 1000. Loss: 2.224569320678711. Accuracy: 25.805864141322164\n",
            "Iteration: 2000. Loss: 2.0187759399414062. Accuracy: 34.49280641048989\n",
            "Iteration: 3000. Loss: 2.0802016258239746. Accuracy: 25.186669094882536\n",
            "Iteration: 4000. Loss: 1.9835275411605835. Accuracy: 47.42305590967037\n",
            "Iteration: 5000. Loss: 1.51662015914917. Accuracy: 40.79402658896376\n",
            "Iteration: 6000. Loss: 1.436682939529419. Accuracy: 57.803678747040614\n",
            "Iteration: 7000. Loss: 1.3447190523147583. Accuracy: 56.98415589145875\n",
            "Iteration: 8000. Loss: 1.346251130104065. Accuracy: 63.1578947368421\n",
            "Iteration: 9000. Loss: 1.2655143737792969. Accuracy: 51.975960662902935\n",
            "Iteration: 10000. Loss: 1.0630393028259277. Accuracy: 60.8085958841741\n",
            "Iteration: 11000. Loss: 1.0911773443222046. Accuracy: 67.14623930067383\n",
            "Iteration: 12000. Loss: 0.7364404797554016. Accuracy: 71.95410672008741\n",
            "Iteration: 13000. Loss: 1.1693074703216553. Accuracy: 68.94918958295392\n",
            "Iteration: 14000. Loss: 0.5972887873649597. Accuracy: 77.52686213804407\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogvr5R8Io2Ic",
        "outputId": "9bfb1f4c-1011-4530-8a05-042c0eaacb58"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torchvision.datasets as dsets\r\n",
        "\r\n",
        "# Hyperparameters\r\n",
        "batch_size = 128\r\n",
        "num_iters = 15000\r\n",
        "input_dim = 28*28 # num_features = 784\r\n",
        "#num_hidden = 100\r\n",
        "output_dim = 10\r\n",
        "\r\n",
        "learning_rate = 0.11\r\n",
        "\r\n",
        "# Device\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "num_epochs = num_iters / (len(train_dataset) / batch_size)\r\n",
        "num_epochs = int(num_epochs)\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \r\n",
        "                                           batch_size=batch_size, \r\n",
        "                                           shuffle=True)   # It's better to shuffle the whole training dataset! \r\n",
        "\r\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \r\n",
        "                                          batch_size=batch_size, \r\n",
        "                                          shuffle=False) \r\n",
        "\r\n",
        "class DeepNeuralNetworkModel(nn.Module):\r\n",
        "    def __init__(self, input_size, num_classes, num_hidden):\r\n",
        "        super().__init__()\r\n",
        "        ### 1st hidden layer: 784 --> 128\r\n",
        "        self.linear_1 = nn.Linear(input_size, num_hidden)\r\n",
        "        ### Non-linearity in 1st hidden layer\r\n",
        "        self.selu_1 = nn.SELU()\r\n",
        "\r\n",
        "        ### 2nd hidden layer: 128 --> 128\r\n",
        "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\r\n",
        "        ### Non-linearity in 2nd hidden layer\r\n",
        "        self.selu_2 = nn.SELU()\r\n",
        "\r\n",
        "        ### 3rd hidden layer: 128 --> 128\r\n",
        "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\r\n",
        "        ### Non-linearity in 3rd hidden layer\r\n",
        "        self.selu_3 = nn.SELU()\r\n",
        "\r\n",
        "\r\n",
        "        ### 4th hidden layer: 128 --> 128\r\n",
        "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\r\n",
        "        ### Non-linearity in 4th hidden layer\r\n",
        "        self.selu_4 = nn.SELU()\r\n",
        "\r\n",
        "        ### Output layer: 128 --> 10\r\n",
        "        self.linear_out = nn.Linear(num_hidden, num_classes)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        ### 1st hidden layer\r\n",
        "        out  = self.linear_1(x)\r\n",
        "        ### Non-linearity in 1st hidden layer\r\n",
        "        out = self.selu_1(out)\r\n",
        "        \r\n",
        "        ### 2nd hidden layer\r\n",
        "        out  = self.linear_2(out)\r\n",
        "        ### Non-linearity in 2nd hidden layer\r\n",
        "        out = self.selu_2(out)\r\n",
        "\r\n",
        "        ### 3rd hidden layer\r\n",
        "        out  = self.linear_3(out)\r\n",
        "        ### Non-linearity in 3rd hidden layer\r\n",
        "        out = self.selu_3(out)\r\n",
        "        \r\n",
        "        ### 4th hidden layer\r\n",
        "        out  = self.linear_4(out)\r\n",
        "        ### Non-linearity in 4th hidden layer\r\n",
        "        out = self.selu_4(out)\r\n",
        "\r\n",
        "        # Linear layer (output)\r\n",
        "        probas  = self.linear_out(out)\r\n",
        "        return probas\r\n",
        "\r\n",
        "# INSTANTIATE MODEL CLASS\r\n",
        "\r\n",
        "model = DeepNeuralNetworkModel(input_size = input_dim,\r\n",
        "                               num_classes = output_dim,\r\n",
        "                               num_hidden = 128)\r\n",
        "# To enable GPU\r\n",
        "model.to(device)\r\n",
        "\r\n",
        "# INSTANTIATE LOSS & OPTIMIZER CLASS\r\n",
        "\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\r\n",
        "\r\n",
        "iter = 0\r\n",
        "for epoch in range(num_epochs):\r\n",
        "    for i, (images, labels) in enumerate(train_loader):\r\n",
        "\r\n",
        "        images = images.view(-1, 28*28).to(device)\r\n",
        "        labels = labels.to(device)\r\n",
        "\r\n",
        "        # Clear gradients w.r.t. parameters\r\n",
        "        optimizer.zero_grad()\r\n",
        "\r\n",
        "        # Forward pass to get output/logits\r\n",
        "        outputs = model(images) \r\n",
        "\r\n",
        "        # Calculate Loss: softmax --> cross entropy loss\r\n",
        "        loss = criterion(outputs, labels)\r\n",
        "\r\n",
        "        # Getting gradients w.r.t. parameters\r\n",
        "        loss.backward()\r\n",
        "\r\n",
        "        # Updating parameters\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        iter += 1\r\n",
        "\r\n",
        "        if iter % 1000 == 0:\r\n",
        "            # Calculate Accuracy         \r\n",
        "            correct = 0\r\n",
        "            total = 0\r\n",
        "            # Iterate through test dataset\r\n",
        "            for images, labels in test_loader:\r\n",
        "               \r\n",
        "                images = images.view(-1, 28*28).to(device)\r\n",
        "\r\n",
        "                # Forward pass only to get logits/output\r\n",
        "                outputs = model(images)\r\n",
        "\r\n",
        "                # Get predictions from the maximum value\r\n",
        "                _, predicted = torch.max(outputs, 1)\r\n",
        "\r\n",
        "                # Total number of labels\r\n",
        "                total += labels.size(0)\r\n",
        "\r\n",
        "\r\n",
        "                # Total correct predictions\r\n",
        "                if torch.cuda.is_available():\r\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum() \r\n",
        "                else:\r\n",
        "                    correct += (predicted == labels).sum()\r\n",
        "\r\n",
        "            accuracy = 100 * correct.item() / total\r\n",
        "\r\n",
        "            # Print Loss\r\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 1000. Loss: 2.3162107467651367. Accuracy: 20.36059005645602\n",
            "Iteration: 2000. Loss: 2.027053117752075. Accuracy: 23.238025860498997\n",
            "Iteration: 3000. Loss: 2.045153856277466. Accuracy: 26.86213804407212\n",
            "Iteration: 4000. Loss: 2.054659843444824. Accuracy: 21.14368967401202\n",
            "Iteration: 5000. Loss: 1.8202632665634155. Accuracy: 49.64487342924786\n",
            "Iteration: 6000. Loss: 1.9556227922439575. Accuracy: 42.57876525223092\n",
            "Iteration: 7000. Loss: 1.4245911836624146. Accuracy: 46.63995629211437\n",
            "Iteration: 8000. Loss: 1.30168879032135. Accuracy: 47.6780185758514\n",
            "Iteration: 9000. Loss: 1.0297679901123047. Accuracy: 67.47404844290658\n",
            "Iteration: 10000. Loss: 1.1112946271896362. Accuracy: 62.81187397559643\n",
            "Iteration: 11000. Loss: 0.900826632976532. Accuracy: 66.49062101620834\n",
            "Iteration: 12000. Loss: 0.8133956789970398. Accuracy: 64.70588235294117\n",
            "Iteration: 13000. Loss: 0.654862105846405. Accuracy: 69.33163358222546\n",
            "Iteration: 14000. Loss: 0.5419927835464478. Accuracy: 76.12456747404845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-U5XJ6apGFA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39qhvvoV2gpn"
      },
      "source": [
        "**4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvIGZ_wmp65a",
        "outputId": "db798d05-f97f-4d49-a526-faa5401b610a"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torchvision.datasets as dsets\r\n",
        "\r\n",
        "# Hyperparameters\r\n",
        "batch_size = 512\r\n",
        "num_iters = 15000\r\n",
        "input_dim = 28*28 # num_features = 784\r\n",
        "#num_hidden = 100\r\n",
        "output_dim = 10\r\n",
        "\r\n",
        "learning_rate = 0.04\r\n",
        "\r\n",
        "# Device\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "num_epochs = num_iters / (len(train_dataset) / batch_size)\r\n",
        "num_epochs = int(num_epochs)\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \r\n",
        "                                           batch_size=batch_size, \r\n",
        "                                           shuffle=True)   # It's better to shuffle the whole training dataset! \r\n",
        "\r\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \r\n",
        "                                          batch_size=batch_size, \r\n",
        "                                          shuffle=False) \r\n",
        "\r\n",
        "class DeepNeuralNetworkModel(nn.Module):\r\n",
        "    def __init__(self, input_size, num_classes, num_hidden):\r\n",
        "        super().__init__()\r\n",
        "        ### 1st hidden layer: 784 --> 128\r\n",
        "        self.linear_1 = nn.Linear(input_size, num_hidden)\r\n",
        "        ### Non-linearity in 1st hidden layer\r\n",
        "        self.selu_1 = nn.SELU()\r\n",
        "\r\n",
        "        ### 2nd hidden layer: 128 --> 128\r\n",
        "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\r\n",
        "        ### Non-linearity in 2nd hidden layer\r\n",
        "        self.selu_2 = nn.SELU()\r\n",
        "\r\n",
        "        ### 3rd hidden layer: 128 --> 128\r\n",
        "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\r\n",
        "        ### Non-linearity in 3rd hidden layer\r\n",
        "        self.selu_3 = nn.SELU()\r\n",
        "\r\n",
        "\r\n",
        "        ### 4th hidden layer: 128 --> 128\r\n",
        "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\r\n",
        "        ### Non-linearity in 4th hidden layer\r\n",
        "        self.selu_4 = nn.SELU()\r\n",
        "\r\n",
        "        ### Output layer: 128 --> 10\r\n",
        "        self.linear_out = nn.Linear(num_hidden, num_classes)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        ### 1st hidden layer\r\n",
        "        out  = self.linear_1(x)\r\n",
        "        ### Non-linearity in 1st hidden layer\r\n",
        "        out = self.selu_1(out)\r\n",
        "        \r\n",
        "        ### 2nd hidden layer\r\n",
        "        out  = self.linear_2(out)\r\n",
        "        ### Non-linearity in 2nd hidden layer\r\n",
        "        out = self.selu_2(out)\r\n",
        "\r\n",
        "        ### 3rd hidden layer\r\n",
        "        out  = self.linear_3(out)\r\n",
        "        ### Non-linearity in 3rd hidden layer\r\n",
        "        out = self.selu_3(out)\r\n",
        "        \r\n",
        "        ### 4th hidden layer\r\n",
        "        out  = self.linear_4(out)\r\n",
        "        ### Non-linearity in 4th hidden layer\r\n",
        "        out = self.selu_4(out)\r\n",
        "\r\n",
        "        # Linear layer (output)\r\n",
        "        probas  = self.linear_out(out)\r\n",
        "        return probas\r\n",
        "\r\n",
        "# INSTANTIATE MODEL CLASS\r\n",
        "\r\n",
        "model = DeepNeuralNetworkModel(input_size = input_dim,\r\n",
        "                               num_classes = output_dim,\r\n",
        "                               num_hidden = 128)\r\n",
        "# To enable GPU\r\n",
        "model.to(device)\r\n",
        "\r\n",
        "# INSTANTIATE LOSS & OPTIMIZER CLASS\r\n",
        "\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\r\n",
        "\r\n",
        "iter = 0\r\n",
        "for epoch in range(num_epochs):\r\n",
        "    for i, (images, labels) in enumerate(train_loader):\r\n",
        "\r\n",
        "        images = images.view(-1, 28*28).to(device)\r\n",
        "        labels = labels.to(device)\r\n",
        "\r\n",
        "        # Clear gradients w.r.t. parameters\r\n",
        "        optimizer.zero_grad()\r\n",
        "\r\n",
        "        # Forward pass to get output/logits\r\n",
        "        outputs = model(images) \r\n",
        "\r\n",
        "        # Calculate Loss: softmax --> cross entropy loss\r\n",
        "        loss = criterion(outputs, labels)\r\n",
        "\r\n",
        "        # Getting gradients w.r.t. parameters\r\n",
        "        loss.backward()\r\n",
        "\r\n",
        "        # Updating parameters\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        iter += 1\r\n",
        "\r\n",
        "        if iter % 1000 == 0:\r\n",
        "            # Calculate Accuracy         \r\n",
        "            correct = 0\r\n",
        "            total = 0\r\n",
        "            # Iterate through test dataset\r\n",
        "            for images, labels in test_loader:\r\n",
        "               \r\n",
        "                images = images.view(-1, 28*28).to(device)\r\n",
        "\r\n",
        "                # Forward pass only to get logits/output\r\n",
        "                outputs = model(images)\r\n",
        "\r\n",
        "                # Get predictions from the maximum value\r\n",
        "                _, predicted = torch.max(outputs, 1)\r\n",
        "\r\n",
        "                # Total number of labels\r\n",
        "                total += labels.size(0)\r\n",
        "\r\n",
        "\r\n",
        "                # Total correct predictions\r\n",
        "                if torch.cuda.is_available():\r\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum() \r\n",
        "                else:\r\n",
        "                    correct += (predicted == labels).sum()\r\n",
        "\r\n",
        "            accuracy = 100 * correct.item() / total\r\n",
        "\r\n",
        "            # Print Loss\r\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 1000. Loss: 2.141386032104492. Accuracy: 27.080677472227283\n",
            "Iteration: 2000. Loss: 1.8769338130950928. Accuracy: 36.113640502640685\n",
            "Iteration: 3000. Loss: 1.875001072883606. Accuracy: 44.782371152795484\n",
            "Iteration: 4000. Loss: 1.7680174112319946. Accuracy: 49.51739209615735\n",
            "Iteration: 5000. Loss: 1.400335431098938. Accuracy: 50.31870333272628\n",
            "Iteration: 6000. Loss: 1.272104024887085. Accuracy: 51.64815152067019\n",
            "Iteration: 7000. Loss: 1.2456040382385254. Accuracy: 62.90293207066108\n",
            "Iteration: 8000. Loss: 1.0494322776794434. Accuracy: 58.44108541249317\n",
            "Iteration: 9000. Loss: 0.9516683220863342. Accuracy: 68.34820615552722\n",
            "Iteration: 10000. Loss: 0.8527882099151611. Accuracy: 72.66435986159169\n",
            "Iteration: 11000. Loss: 0.8400475382804871. Accuracy: 70.33327262793662\n",
            "Iteration: 12000. Loss: 0.7506067752838135. Accuracy: 76.37953014022946\n",
            "Iteration: 13000. Loss: 0.6592952013015747. Accuracy: 75.83318156984156\n",
            "Iteration: 14000. Loss: 0.5661241412162781. Accuracy: 81.58805317792752\n",
            "Iteration: 15000. Loss: 0.5004908442497253. Accuracy: 80.84137679839738\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xlp0ieiRp96Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dfa44d0-af08-4cdc-afff-a2c8c98b00f5"
      },
      "source": [
        "num_epochs = num_iters / (len(train_dataset) / 512)\r\n",
        "num_epochs = int(num_epochs)\r\n",
        "num_epochs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "155"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BElRMTP80EaG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}